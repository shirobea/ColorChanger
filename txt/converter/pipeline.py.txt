"""変換パイプライン（リサイズ + パレット写像のみ）。"""

from __future__ import annotations

from typing import Callable, Tuple
import threading

import numpy as np

from palette import BeadPalette
from .io_utils import (
    _compute_resize,
    _load_image_rgb,
    _load_normal_map_rgb,
    _load_ao_map_gray,
    _load_specular_map_gray,
    _load_displacement_map_gray,
)
from .quantize import _map_centers_to_palette, _report

ProgressCb = Callable[[float], None]
CancelEvent = threading.Event
Size = Tuple[int, int]
PACKED_UNIQUE_THRESHOLD = 2_000_000

ALL_MODE_SPECS = [
    {"label": "なし", "mode": "none"},
    {"label": "RGB", "mode": "RGB"},
    {"label": "Lab2000", "mode": "Lab", "lab_metric": "CIEDE2000"},
    {"label": "Lab94", "mode": "Lab", "lab_metric": "CIE94"},
    {"label": "Lab76", "mode": "Lab", "lab_metric": "CIE76"},
    {"label": "Hunter", "mode": "Hunter"},
    {"label": "Oklab", "mode": "Oklab"},
    {"label": "CMC", "mode": "CMC(l:c)"},
]


class ConversionCancelled(Exception):
    """ユーザーによる中断を示す例外。"""


def _require_cv2():
    try:
        import cv2  # type: ignore
    except Exception as exc:
        raise RuntimeError("OpenCV (cv2) が必要です。pip install opencv-python") from exc
    return cv2


def _map_image_to_palette(
    image_rgb: np.ndarray,
    palette: BeadPalette,
    mode: str,
    rgb_weights: tuple[float, float, float] = (1.0, 1.0, 1.0),
    lab_metric: str = "CIEDE2000",
    cmc_l: float = 2.0,
    cmc_c: float = 1.0,
    progress_callback: ProgressCb | None = None,
    progress_range: tuple[float, float] = (0.3, 1.0),
    cancel_event: CancelEvent | None = None,
) -> np.ndarray:
    """減色せず、各画素を最短距離のパレット色へ写像する。"""
    start, end = progress_range
    _report(progress_callback, start, cancel_event)

    flat = image_rgb.reshape(-1, 3)
    total_pixels = flat.shape[0]
    if total_pixels > PACKED_UNIQUE_THRESHOLD:
        flat_u32 = flat.astype(np.uint32, copy=False)
        codes = (flat_u32[:, 0] << 16) | (flat_u32[:, 1] << 8) | flat_u32[:, 2]
        unique_codes, inv = np.unique(codes, return_inverse=True)
        centers = np.stack(
            (
                (unique_codes >> 16) & 0xFF,
                (unique_codes >> 8) & 0xFF,
                unique_codes & 0xFF,
            ),
            axis=1,
        ).astype(np.float32)
    else:
        centers, inv = np.unique(flat, axis=0, return_inverse=True)
        centers = centers.astype(np.float32, copy=False)
    mapping = _map_centers_to_palette(
        centers,
        palette,
        mode,
        progress_callback=progress_callback,
        progress_range=(start, end),
        cancel_event=cancel_event,
        cmc_l=cmc_l,
        cmc_c=cmc_c,
        rgb_weights=rgb_weights,
        lab_metric=lab_metric,
    )
    mapped = palette.rgb_array[mapping].astype(np.uint8)[inv].reshape(image_rgb.shape)
    _report(progress_callback, end, cancel_event)
    return mapped


def _normalize_normals(normal_rgb: np.ndarray, invert_y: bool) -> np.ndarray:
    """ノーマルマップを[-1, 1]に変換して正規化する。"""
    normals = normal_rgb.astype(np.float32) / 255.0
    normals = normals * 2.0 - 1.0
    if invert_y:
        normals[:, :, 1] *= -1.0
    length = np.linalg.norm(normals, axis=2, keepdims=True)
    normals = normals / np.clip(length, 1e-6, None)
    return normals


def _apply_normal_shading(
    image_rgb: np.ndarray,
    normal_rgb: np.ndarray,
    light_dir: tuple[float, float, float],
    strength: float,
    ambient: float,
    gamma: float,
    invert_y: bool,
    ao_gray: np.ndarray | None,
    ao_strength: float,
) -> np.ndarray:
    """ノーマルマップ由来の陰影を明度に反映する。"""
    cv2 = _require_cv2()
    light = np.array(light_dir, dtype=np.float32)
    if np.linalg.norm(light) < 1e-6:
        light = np.array([0.0, 0.0, 1.0], dtype=np.float32)
    light = light / np.linalg.norm(light)

    normals = _normalize_normals(normal_rgb, invert_y)
    shade = np.sum(normals * light[None, None, :], axis=2)
    shade = np.clip(shade, 0.0, 1.0)
    shade = float(ambient) + (1.0 - float(ambient)) * shade
    if ao_gray is not None:
        ao_strength = max(0.0, min(1.0, float(ao_strength)))
        shade = shade * ((1.0 - ao_strength) + ao_strength * ao_gray)
    shade = shade ** max(float(gamma), 1e-3)

    # LabのLだけ補正して色味を保つ
    bgr = image_rgb[:, :, ::-1].astype(np.float32) / 255.0
    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2Lab)
    l = lab[:, :, 0]
    strength = max(0.0, float(strength))
    l = np.clip(l * (1.0 + strength * (shade - 0.5)), 0.0, 100.0)
    lab[:, :, 0] = l
    bgr_out = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)
    rgb_out = np.clip(bgr_out[:, :, ::-1] * 255.0, 0, 255).astype(np.uint8)
    return rgb_out


def _apply_ao_shading(image_rgb: np.ndarray, ao_gray: np.ndarray, ao_strength: float) -> np.ndarray:
    """AOマップで明度だけを調整する。"""
    cv2 = _require_cv2()
    ao_strength = max(0.0, min(1.0, float(ao_strength)))
    bgr = image_rgb[:, :, ::-1].astype(np.float32) / 255.0
    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2Lab)
    l = lab[:, :, 0]
    l = np.clip(l * ((1.0 - ao_strength) + ao_strength * ao_gray), 0.0, 100.0)
    lab[:, :, 0] = l
    bgr_out = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)
    rgb_out = np.clip(bgr_out[:, :, ::-1] * 255.0, 0, 255).astype(np.uint8)
    return rgb_out


def _apply_displacement_shading(
    image_rgb: np.ndarray,
    displacement_gray: np.ndarray,
    strength: float,
    midpoint: float,
    invert: bool,
) -> np.ndarray:
    """Displacementマップで明度を押し出すように補正する。"""
    cv2 = _require_cv2()
    strength = max(0.0, float(strength))
    midpoint = max(0.0, min(1.0, float(midpoint)))
    height = displacement_gray
    if invert:
        height = 1.0 - height
    offset = (height - midpoint) * 2.0
    factor = 1.0 + strength * offset
    factor = np.clip(factor, 0.0, 2.0)
    bgr = image_rgb[:, :, ::-1].astype(np.float32) / 255.0
    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2Lab)
    l = lab[:, :, 0]
    l = np.clip(l * factor, 0.0, 100.0)
    lab[:, :, 0] = l
    bgr_out = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)
    rgb_out = np.clip(bgr_out[:, :, ::-1] * 255.0, 0, 255).astype(np.uint8)
    return rgb_out


def _apply_specular_highlight(
    image_rgb: np.ndarray,
    normal_rgb: np.ndarray | None,
    light_dir: tuple[float, float, float],
    strength: float,
    shininess: float,
    invert_y: bool,
    specular_gray: np.ndarray,
) -> np.ndarray:
    """Specularマップと法線でハイライトを加える。"""
    cv2 = _require_cv2()
    strength = max(0.0, float(strength))
    shininess = max(1.0, float(shininess))

    if normal_rgb is None:
        normals = np.zeros((*specular_gray.shape, 3), dtype=np.float32)
        normals[:, :, 2] = 1.0
    else:
        normals = _normalize_normals(normal_rgb, invert_y)

    light = np.array(light_dir, dtype=np.float32)
    if np.linalg.norm(light) < 1e-6:
        light = np.array([0.0, 0.0, 1.0], dtype=np.float32)
    light = light / np.linalg.norm(light)
    view = np.array([0.0, 0.0, 1.0], dtype=np.float32)
    half = light + view
    if np.linalg.norm(half) < 1e-6:
        half = view
    half = half / np.linalg.norm(half)

    dot = np.sum(normals * half[None, None, :], axis=2)
    spec = np.clip(dot, 0.0, 1.0) ** shininess
    spec_factor = np.clip(spec * specular_gray * strength, 0.0, 1.0)

    bgr = image_rgb[:, :, ::-1].astype(np.float32) / 255.0
    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2Lab)
    l = lab[:, :, 0]
    l = np.clip(l + (100.0 - l) * spec_factor, 0.0, 100.0)
    lab[:, :, 0] = l
    bgr_out = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)
    rgb_out = np.clip(bgr_out[:, :, ::-1] * 255.0, 0, 255).astype(np.uint8)
    return rgb_out


def apply_shading_preview(
    image_rgb: np.ndarray,
    normal_map_path: str | None = None,
    normal_enabled: bool = False,
    normal_invert_y: bool = False,
    normal_light_dir: tuple[float, float, float] = (0.2, -0.2, 0.95),
    normal_strength: float = 0.6,
    normal_ambient: float = 0.25,
    normal_gamma: float = 1.0,
    ao_map_path: str | None = None,
    ao_enabled: bool = False,
    ao_strength: float = 0.6,
    specular_map_path: str | None = None,
    specular_enabled: bool = False,
    specular_strength: float = 0.6,
    specular_shininess: float = 24.0,
    displacement_map_path: str | None = None,
    displacement_enabled: bool = False,
    displacement_strength: float = 0.6,
    displacement_midpoint: float = 0.5,
    displacement_invert: bool = False,
) -> np.ndarray:
    """入力画像にノーマル/AO/Specular/Displacementの明度補正だけを適用する（プレビュー用）。"""
    if image_rgb is None:
        raise ValueError("image_rgb が必要です。")
    if not (normal_enabled or ao_enabled or specular_enabled or displacement_enabled):
        return np.asarray(image_rgb, dtype=np.uint8)
    cv2 = _require_cv2()
    base = np.asarray(image_rgb, dtype=np.uint8)
    height, width = base.shape[:2]

    ao_gray = None
    if ao_enabled and ao_map_path:
        ao_gray = _load_ao_map_gray(ao_map_path)
        ao_gray = cv2.resize(ao_gray, (width, height), interpolation=cv2.INTER_LINEAR)

    normal_rgb = None
    if (normal_enabled or specular_enabled) and normal_map_path:
        normal_rgb = _load_normal_map_rgb(normal_map_path)
        normal_rgb = cv2.resize(normal_rgb, (width, height), interpolation=cv2.INTER_LINEAR)
    if normal_enabled and normal_rgb is not None:
        base = _apply_normal_shading(
            base,
            normal_rgb,
            light_dir=normal_light_dir,
            strength=normal_strength,
            ambient=normal_ambient,
            gamma=normal_gamma,
            invert_y=normal_invert_y,
            ao_gray=ao_gray,
            ao_strength=ao_strength,
        )
    elif ao_gray is not None:
        base = _apply_ao_shading(base, ao_gray, ao_strength)

    specular_gray = None
    if specular_enabled and specular_map_path:
        specular_gray = _load_specular_map_gray(specular_map_path)
        specular_gray = cv2.resize(specular_gray, (width, height), interpolation=cv2.INTER_LINEAR)
    if specular_gray is not None and specular_enabled:
        base = _apply_specular_highlight(
            base,
            normal_rgb,
            light_dir=normal_light_dir,
            strength=specular_strength,
            shininess=specular_shininess,
            invert_y=normal_invert_y,
            specular_gray=specular_gray,
        )

    if displacement_enabled and displacement_map_path:
        disp_gray = _load_displacement_map_gray(displacement_map_path)
        disp_gray = cv2.resize(disp_gray, (width, height), interpolation=cv2.INTER_LINEAR)
        base = _apply_displacement_shading(
            base,
            disp_gray,
            strength=displacement_strength,
            midpoint=displacement_midpoint,
            invert=displacement_invert,
        )

    return base


def convert_image(
    input_path: str | None,
    output_size: int | Tuple[int, int],
    mode: str,
    palette: BeadPalette,
    keep_aspect: bool = True,
    resize_method: str = "nearest",
    lab_metric: str = "CIEDE2000",
    cmc_l: float = 2.0,
    cmc_c: float = 1.0,
    rgb_weights: tuple[float, float, float] = (1.0, 1.0, 1.0),
    progress_callback: ProgressCb | None = None,
    cancel_event: CancelEvent | None = None,
    input_image: np.ndarray | None = None,
    normal_map_path: str | None = None,
    normal_enabled: bool = False,
    normal_invert_y: bool = False,
    normal_light_dir: tuple[float, float, float] = (0.2, -0.2, 0.95),
    normal_strength: float = 0.6,
    normal_ambient: float = 0.25,
    normal_gamma: float = 1.0,
    ao_map_path: str | None = None,
    ao_enabled: bool = False,
    ao_strength: float = 0.6,
    specular_map_path: str | None = None,
    specular_enabled: bool = False,
    specular_strength: float = 0.6,
    specular_shininess: float = 24.0,
    displacement_map_path: str | None = None,
    displacement_enabled: bool = False,
    displacement_strength: float = 0.6,
    displacement_midpoint: float = 0.5,
    displacement_invert: bool = False,
) -> np.ndarray:
    """入力画像を指定サイズへリサイズし、パレットへ写像して返す。"""
    _report(progress_callback, 0.0, cancel_event)
    cv2 = _require_cv2()
    if input_image is not None:
        # 事前ノイズ除去などで渡されたRGB配列を優先する
        image_rgb = np.asarray(input_image, dtype=np.uint8)
    else:
        if input_path is None:
            raise ValueError("input_image または input_path を指定してください。")
        image_rgb = _load_image_rgb(input_path)
    orig_h, orig_w = image_rgb.shape[:2]
    target_w, target_h = _compute_resize((orig_h, orig_w), output_size, keep_aspect)

    interp_map = {
        "nearest": cv2.INTER_NEAREST,
        "bilinear": cv2.INTER_LINEAR,
        "bicubic": cv2.INTER_CUBIC,
    }
    interp = interp_map.get(resize_method.lower(), cv2.INTER_NEAREST)

    resized = cv2.resize(image_rgb, (target_w, target_h), interpolation=interp)
    _report(progress_callback, 0.3, cancel_event)

    mode_lower = mode.lower()
    ao_gray = None
    if ao_enabled and ao_map_path:
        ao_gray = _load_ao_map_gray(ao_map_path)
        ao_gray = cv2.resize(ao_gray, (target_w, target_h), interpolation=cv2.INTER_LINEAR)

    normal_rgb = None
    if (normal_enabled or specular_enabled) and normal_map_path:
        normal_rgb = _load_normal_map_rgb(normal_map_path)
        normal_rgb = cv2.resize(normal_rgb, (target_w, target_h), interpolation=cv2.INTER_LINEAR)

    base = resized
    if normal_enabled and normal_rgb is not None:
        base = _apply_normal_shading(
            resized,
            normal_rgb,
            light_dir=normal_light_dir,
            strength=normal_strength,
            ambient=normal_ambient,
            gamma=normal_gamma,
            invert_y=normal_invert_y,
            ao_gray=ao_gray,
            ao_strength=ao_strength,
        )
    elif ao_gray is not None:
        base = _apply_ao_shading(resized, ao_gray, ao_strength)

    specular_gray = None
    if specular_enabled and specular_map_path:
        specular_gray = _load_specular_map_gray(specular_map_path)
        specular_gray = cv2.resize(specular_gray, (target_w, target_h), interpolation=cv2.INTER_LINEAR)
    if specular_gray is not None and specular_enabled:
        base = _apply_specular_highlight(
            base,
            normal_rgb,
            light_dir=normal_light_dir,
            strength=specular_strength,
            shininess=specular_shininess,
            invert_y=normal_invert_y,
            specular_gray=specular_gray,
        )
    if displacement_enabled and displacement_map_path:
        disp_gray = _load_displacement_map_gray(displacement_map_path)
        disp_gray = cv2.resize(disp_gray, (target_w, target_h), interpolation=cv2.INTER_LINEAR)
        base = _apply_displacement_shading(
            base,
            disp_gray,
            strength=displacement_strength,
            midpoint=displacement_midpoint,
            invert=displacement_invert,
        )

    if mode_lower in {"none", "なし"}:
        _report(progress_callback, 1.0, cancel_event)
        return base

    mapped = _map_image_to_palette(
        base,
        palette,
        mode,
        rgb_weights=rgb_weights,
        lab_metric=lab_metric,
        cmc_l=cmc_l,
        cmc_c=cmc_c,
        progress_callback=progress_callback,
        progress_range=(0.3, 1.0),
        cancel_event=cancel_event,
    )
    _report(progress_callback, 1.0, cancel_event)
    return mapped


def convert_all_modes(
    input_path: str | None,
    output_size: int | Tuple[int, int],
    palette: BeadPalette,
    keep_aspect: bool = True,
    resize_method: str = "nearest",
    cmc_l: float = 2.0,
    cmc_c: float = 1.0,
    rgb_weights: tuple[float, float, float] = (1.0, 1.0, 1.0),
    progress_callback: ProgressCb | None = None,
    cancel_event: CancelEvent | None = None,
    input_image: np.ndarray | None = None,
    normal_map_path: str | None = None,
    normal_enabled: bool = False,
    normal_invert_y: bool = False,
    normal_light_dir: tuple[float, float, float] = (0.2, -0.2, 0.95),
    normal_strength: float = 0.6,
    normal_ambient: float = 0.25,
    normal_gamma: float = 1.0,
    ao_map_path: str | None = None,
    ao_enabled: bool = False,
    ao_strength: float = 0.6,
    specular_map_path: str | None = None,
    specular_enabled: bool = False,
    specular_strength: float = 0.6,
    specular_shininess: float = 24.0,
    displacement_map_path: str | None = None,
    displacement_enabled: bool = False,
    displacement_strength: float = 0.6,
    displacement_midpoint: float = 0.5,
    displacement_invert: bool = False,
) -> list[dict[str, np.ndarray]]:
    """全ての変換モードで処理した結果を順番に返す。"""
    _report(progress_callback, 0.0, cancel_event)
    cv2 = _require_cv2()
    if input_image is not None:
        # 事前ノイズ除去などで渡されたRGB配列を優先する
        image_rgb = np.asarray(input_image, dtype=np.uint8)
    else:
        if input_path is None:
            raise ValueError("input_image または input_path を指定してください。")
        image_rgb = _load_image_rgb(input_path)
    orig_h, orig_w = image_rgb.shape[:2]
    target_w, target_h = _compute_resize((orig_h, orig_w), output_size, keep_aspect)

    interp_map = {
        "nearest": cv2.INTER_NEAREST,
        "bilinear": cv2.INTER_LINEAR,
        "bicubic": cv2.INTER_CUBIC,
    }
    interp = interp_map.get(resize_method.lower(), cv2.INTER_NEAREST)

    resized = cv2.resize(image_rgb, (target_w, target_h), interpolation=interp)
    _report(progress_callback, 0.2, cancel_event)

    ao_gray = None
    if ao_enabled and ao_map_path:
        ao_gray = _load_ao_map_gray(ao_map_path)
        ao_gray = cv2.resize(ao_gray, (target_w, target_h), interpolation=cv2.INTER_LINEAR)

    normal_rgb = None
    if (normal_enabled or specular_enabled) and normal_map_path:
        normal_rgb = _load_normal_map_rgb(normal_map_path)
        normal_rgb = cv2.resize(normal_rgb, (target_w, target_h), interpolation=cv2.INTER_LINEAR)

    base = resized
    if normal_enabled and normal_rgb is not None:
        base = _apply_normal_shading(
            resized,
            normal_rgb,
            light_dir=normal_light_dir,
            strength=normal_strength,
            ambient=normal_ambient,
            gamma=normal_gamma,
            invert_y=normal_invert_y,
            ao_gray=ao_gray,
            ao_strength=ao_strength,
        )
    elif ao_gray is not None:
        base = _apply_ao_shading(resized, ao_gray, ao_strength)

    specular_gray = None
    if specular_enabled and specular_map_path:
        specular_gray = _load_specular_map_gray(specular_map_path)
        specular_gray = cv2.resize(specular_gray, (target_w, target_h), interpolation=cv2.INTER_LINEAR)
    if specular_gray is not None and specular_enabled:
        base = _apply_specular_highlight(
            base,
            normal_rgb,
            light_dir=normal_light_dir,
            strength=specular_strength,
            shininess=specular_shininess,
            invert_y=normal_invert_y,
            specular_gray=specular_gray,
        )
    if displacement_enabled and displacement_map_path:
        disp_gray = _load_displacement_map_gray(displacement_map_path)
        disp_gray = cv2.resize(disp_gray, (target_w, target_h), interpolation=cv2.INTER_LINEAR)
        base = _apply_displacement_shading(
            base,
            disp_gray,
            strength=displacement_strength,
            midpoint=displacement_midpoint,
            invert=displacement_invert,
        )

    results: list[dict[str, np.ndarray]] = []
    total = len(ALL_MODE_SPECS)
    span = 0.8 / max(1, total)
    for idx, spec in enumerate(ALL_MODE_SPECS):
        start = 0.2 + span * idx
        end = start + span
        mode = str(spec.get("mode", ""))
        label = str(spec.get("label", ""))
        if mode.lower() in {"none", "なし"}:
            # 変換なしはリサイズ結果をそのまま使う
            _report(progress_callback, start, cancel_event)
            results.append({"label": label, "image": base.copy()})
            _report(progress_callback, end, cancel_event)
            continue
        mapped = _map_image_to_palette(
            base,
            palette,
            mode,
            rgb_weights=rgb_weights,
            lab_metric=str(spec.get("lab_metric", "CIEDE2000")),
            cmc_l=cmc_l,
            cmc_c=cmc_c,
            progress_callback=progress_callback,
            progress_range=(start, end),
            cancel_event=cancel_event,
        )
        results.append({"label": label, "image": mapped})

    _report(progress_callback, 1.0, cancel_event)
    return results
